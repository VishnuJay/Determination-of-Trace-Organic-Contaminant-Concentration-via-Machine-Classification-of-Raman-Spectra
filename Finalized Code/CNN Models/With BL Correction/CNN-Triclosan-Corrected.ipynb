{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5953c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import KeyFunctions as me\n",
    "import tensorflow as tf\n",
    "RandState = 117\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b201c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Full Triclosan Dataset\n",
    "df, labels = me.ConstructCombinedTriclosanDataset()\n",
    "df = me.BaselineCorrection(me.BaselineCorrection(df))\n",
    "\n",
    "[train, test] = train_test_split(df, random_state = RandState, shuffle = True, train_size = 0.8)\n",
    "\n",
    "y_tn = train.index\n",
    "y_tt = test.index\n",
    "X_tt = test.to_numpy()\n",
    "X_tn = train.to_numpy()\n",
    "\n",
    "#Augment Data to 4000 Spectra\n",
    "X_tnAu, y_tnAu = me.AugmentData(X_tn, y_tn, 4000, df.columns.to_numpy(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187a01c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-5    11\n",
       "10-3    10\n",
       "10-4    10\n",
       "10-9     9\n",
       "10-7     6\n",
       "10-8     6\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdef8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Training Parameters\n",
    "verbose = 1\n",
    "epochsvec = [5, 20, 50]\n",
    "batch_sizevec = [10, 50, 100]\n",
    "epochs = epochsvec[1]\n",
    "batch_size = batch_sizevec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479b91a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 901, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([11, 901, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([11, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale X-Data with Training Xs\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tnAu)\n",
    "X_tnS = scaler.transform(X_tnAu)\n",
    "X_ttS = scaler.transform(X_tt)\n",
    "\n",
    "#Encode y-Data with Training ys\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_tnAu)\n",
    "y_tn_e = encoder.transform(y_tnAu)\n",
    "y_tn_p = np_utils.to_categorical(y_tn_e, num_classes = len(labels))\n",
    "y_tt_e = encoder.transform(y_tt)\n",
    "y_tt_p = np_utils.to_categorical(y_tt_e, num_classes = len(labels))\n",
    "\n",
    "\n",
    "#Reshape All Data to a 3D Tensor of Shape [Number of Spectra, Number of Timesteps(1), Number of Wavelengths]\n",
    "X_tn_p = X_tnS.reshape(X_tnS.shape[0], X_tnS.shape[1], 1)\n",
    "X_tt_p = X_ttS.reshape(X_ttS.shape[0], X_ttS.shape[1], 1)\n",
    "\n",
    "y_tnT = tf.convert_to_tensor(y_tn_p)\n",
    "y_ttT = tf.convert_to_tensor(y_tt_p)\n",
    "X_tnT = tf.convert_to_tensor(X_tn_p)\n",
    "X_ttT = tf.convert_to_tensor(X_tt_p)\n",
    "\n",
    "display(X_tnT.shape)\n",
    "display(y_tnT.shape)\n",
    "display(X_ttT.shape)\n",
    "display(y_ttT.shape)\n",
    "\n",
    "ytruth = tf.argmax(input = y_ttT, axis = 1).numpy()\n",
    "ytruth = encoder.inverse_transform(ytruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374fecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 7s 107ms/step - loss: 0.1018 - accuracy: 0.9650 - val_loss: 2.5341e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 1.7429e-05 - accuracy: 1.0000 - val_loss: 1.5824e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 1.1421e-05 - accuracy: 1.0000 - val_loss: 1.3248e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 9.2965e-06 - accuracy: 1.0000 - val_loss: 1.1784e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 8.2282e-06 - accuracy: 1.0000 - val_loss: 1.0682e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 7s 108ms/step - loss: 7.4829e-06 - accuracy: 1.0000 - val_loss: 9.7113e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 6.2773e-06 - accuracy: 1.0000 - val_loss: 8.8894e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 6s 94ms/step - loss: 5.7860e-06 - accuracy: 1.0000 - val_loss: 8.1536e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 6s 100ms/step - loss: 5.2666e-06 - accuracy: 1.0000 - val_loss: 7.5161e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 4.5070e-06 - accuracy: 1.0000 - val_loss: 6.9488e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 6s 100ms/step - loss: 4.1578e-06 - accuracy: 1.0000 - val_loss: 6.4566e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 6s 95ms/step - loss: 3.7578e-06 - accuracy: 1.0000 - val_loss: 5.9859e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 3.4540e-06 - accuracy: 1.0000 - val_loss: 5.5802e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 7s 105ms/step - loss: 3.1557e-06 - accuracy: 1.0000 - val_loss: 5.2059e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 2.9572e-06 - accuracy: 1.0000 - val_loss: 4.8528e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 2.5770e-06 - accuracy: 1.0000 - val_loss: 4.5541e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 2.3515e-06 - accuracy: 1.0000 - val_loss: 4.2798e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 2.2411e-06 - accuracy: 1.0000 - val_loss: 4.0255e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 7s 103ms/step - loss: 2.0476e-06 - accuracy: 1.0000 - val_loss: 3.7982e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 1.9414e-06 - accuracy: 1.0000 - val_loss: 3.5816e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 5.9537 - accuracy: 0.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5454545617103577"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Multi-class Classification with Keras\n",
    " \n",
    "n_timesteps, n_features, n_outputs = X_tn_p.shape[1], X_tn_p.shape[2], y_tn_p.shape[1]\n",
    "\n",
    "#Define Sequential Model - 1 Convolution Layer, 1 Dropout Layer, 1 Flatten Layer, 2 Dense Layers\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Implement EarlyStopping\n",
    "stopper = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",patience = 2,verbose = 0, restore_best_weights = True)\n",
    "\n",
    "#Fit Model\n",
    "model.fit(X_tnT, y_tnT, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split = 0.2, callbacks = stopper)\n",
    "\n",
    "#Evaluate Model\n",
    "_, SCaccuracy = model.evaluate(X_ttT, y_ttT, batch_size=batch_size, verbose=verbose)\n",
    "display(SCaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ccf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Prediction\n",
    "SCypred = model.predict(X_ttT)\n",
    "SCypred = tf.argmax(input = SCypred, axis = 1).numpy()\n",
    "SCypred = encoder.inverse_transform(SCypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b7e0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.260674  , 0.06863199, ..., 0.05131504,\n",
       "         0.22697566, 0.        ],\n",
       "        [0.        , 0.25130126, 0.04998049, ..., 0.16755699,\n",
       "         0.17196947, 0.        ],\n",
       "        [0.08547481, 0.02918387, 0.03943924, ..., 0.09827796,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.0259135 , 0.14349277, 0.03860227, ..., 0.1464171 ,\n",
       "         0.06791373, 0.        ],\n",
       "        [0.0584053 , 0.        , 0.00368386, ..., 0.07261916,\n",
       "         0.        , 0.        ],\n",
       "        [0.00071223, 0.        , 0.        , ..., 0.00055261,\n",
       "         0.        , 0.06282327]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract Convolution Feature Maps\n",
    "convlayer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "\n",
    "spectra = X_ttT[n, :, 0]\n",
    "specvec = list()\n",
    "specvec.append(spectra)\n",
    "spectra = tf.reshape(spectra, (1, len(spectra), 1))\n",
    "\n",
    "SCfeature_maps = convlayer.predict(spectra)\n",
    "display(SCfeature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53fd3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 1802, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([11, 1802, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([11, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Apply Fourier Transform to Training and Testing Data\n",
    "X_tnf = np.apply_along_axis(np.fft.fft, axis=1, arr=X_tnAu)\n",
    "X_ttf = np.apply_along_axis(np.fft.fft, axis=1, arr=X_tt)\n",
    "\n",
    "#Combine Real and Imaginary Part of FT in form [real, imaginary]\n",
    "X_tnf = np.append(X_tnf.real, X_tnf.imag, axis = 1)\n",
    "X_ttf = np.append(X_ttf.real, X_ttf.imag, axis = 1)\n",
    "X_tnf= X_tnf.astype('float32')\n",
    "X_ttf= X_ttf.astype('float32')\n",
    "\n",
    "#Scale X-Data with Training Xs\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tnf)\n",
    "X_tnf = scaler.transform(X_tnf)\n",
    "X_ttf = scaler.transform(X_ttf)\n",
    "\n",
    "#Encode y-Data with Training ys\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_tnAu)\n",
    "y_tn_e = encoder.transform(y_tnAu)\n",
    "y_tn_p = np_utils.to_categorical(y_tn_e, num_classes = len(labels))\n",
    "y_tt_e = encoder.transform(y_tt)\n",
    "y_tt_p = np_utils.to_categorical(y_tt_e, num_classes = len(labels))\n",
    "\n",
    "#Reshape All Data to a 3D Tensor of Shape [Number of Spectra, Number of Timesteps(1), Number of Wavelengths]\n",
    "X_tn_p = X_tnf.reshape(X_tnf.shape[0], X_tnf.shape[1], 1)\n",
    "X_tt_p = X_ttf.reshape(X_ttf.shape[0], X_ttf.shape[1], 1)\n",
    "\n",
    "y_tnT = tf.convert_to_tensor(y_tn_p)\n",
    "y_ttT = tf.convert_to_tensor(y_tt_p)\n",
    "X_tnT = tf.convert_to_tensor(X_tn_p)\n",
    "X_ttT = tf.convert_to_tensor(X_tt_p)\n",
    "\n",
    "\n",
    "display(X_tnT.shape)\n",
    "display(y_tnT.shape)\n",
    "display(X_ttT.shape)\n",
    "display(y_ttT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e552db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 13s 196ms/step - loss: 0.2733 - accuracy: 0.9259 - val_loss: 6.8607e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 13s 200ms/step - loss: 1.2972e-04 - accuracy: 1.0000 - val_loss: 4.1325e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 12s 183ms/step - loss: 8.6668e-05 - accuracy: 1.0000 - val_loss: 3.2247e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 12s 183ms/step - loss: 6.5533e-05 - accuracy: 1.0000 - val_loss: 2.5682e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 13s 200ms/step - loss: 5.0408e-05 - accuracy: 1.0000 - val_loss: 2.1152e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 4.0549e-05 - accuracy: 1.0000 - val_loss: 1.7675e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 13s 196ms/step - loss: 3.2560e-05 - accuracy: 1.0000 - val_loss: 1.5110e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 12s 188ms/step - loss: 2.6755e-05 - accuracy: 1.0000 - val_loss: 1.3121e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 13s 211ms/step - loss: 2.2374e-05 - accuracy: 1.0000 - val_loss: 1.1569e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 14s 224ms/step - loss: 1.9259e-05 - accuracy: 1.0000 - val_loss: 1.0275e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 13s 199ms/step - loss: 1.6420e-05 - accuracy: 1.0000 - val_loss: 9.1788e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.4786e-05 - accuracy: 1.0000 - val_loss: 8.2744e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 11s 179ms/step - loss: 1.2421e-05 - accuracy: 1.0000 - val_loss: 7.5235e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 12s 184ms/step - loss: 1.1042e-05 - accuracy: 1.0000 - val_loss: 6.8864e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 12s 191ms/step - loss: 9.8434e-06 - accuracy: 1.0000 - val_loss: 6.3133e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 12s 189ms/step - loss: 9.2039e-06 - accuracy: 1.0000 - val_loss: 5.8251e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 11s 178ms/step - loss: 8.0919e-06 - accuracy: 1.0000 - val_loss: 5.3669e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 12s 184ms/step - loss: 7.1719e-06 - accuracy: 1.0000 - val_loss: 4.9898e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 12s 191ms/step - loss: 6.6641e-06 - accuracy: 1.0000 - val_loss: 4.6606e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 12s 187ms/step - loss: 6.0924e-06 - accuracy: 1.0000 - val_loss: 4.3446e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.9394 - accuracy: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6363636255264282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Multi-class Classification with Keras\n",
    " \n",
    "n_timesteps, n_features, n_outputs = X_tn_p.shape[1], X_tn_p.shape[2], y_tn_p.shape[1]\n",
    "\n",
    "#Define Sequential Model - 1 Convolution Layer, 1 Dropout Layer, 1 Flatten Layer, 2 Dense Layers\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Implement EarlyStopping\n",
    "stopper = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",patience = 2,verbose = 0, restore_best_weights = True)\n",
    "\n",
    "#Fit Model\n",
    "model.fit(X_tnT, y_tnT, epochs=epochs, batch_size=batch_size, verbose=verbose,  validation_split=0.2, callbacks = stopper)\n",
    "\n",
    "#Evaluate Model\n",
    "_, FTaccuracy = model.evaluate(X_ttT, y_ttT, batch_size=batch_size, verbose=verbose)\n",
    "display(FTaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54173aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Prediction\n",
    "FTypred = model.predict(X_ttT)\n",
    "FTypred = tf.argmax(input = FTypred, axis = 1).numpy()\n",
    "FTypred = encoder.inverse_transform(FTypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0580f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2_input (InputLayer)  [(None, 1802, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1800, 64)          256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.00422935, 0.10867103, 0.        , ..., 0.01488325,\n",
       "         0.        , 0.00630847],\n",
       "        [0.        , 0.16611724, 0.        , ..., 0.04071415,\n",
       "         0.04526045, 0.07095192],\n",
       "        [0.        , 0.14044341, 0.        , ..., 0.        ,\n",
       "         0.13208564, 0.06784447],\n",
       "        ...,\n",
       "        [0.        , 0.00634472, 0.04545243, ..., 0.        ,\n",
       "         0.10038912, 0.01804178],\n",
       "        [0.        , 0.        , 0.07181382, ..., 0.01811103,\n",
       "         0.04018268, 0.00832233],\n",
       "        [0.02018333, 0.00538357, 0.01623065, ..., 0.        ,\n",
       "         0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convlayer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "convlayer.summary()\n",
    "\n",
    "spectra = X_ttT[n, :, 0]\n",
    "specvec.append(spectra)\n",
    "spectra = tf.reshape(spectra, (1, len(spectra), 1))\n",
    "\n",
    "FTfeature_maps = convlayer.predict(spectra)\n",
    "display(FTfeature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "756a0320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 1024, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([11, 1024, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([11, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Apply Welsh-Hadamard Transform to Training and Testing Data\n",
    "from sympy.discrete.transforms import fwht, ifwht\n",
    "\n",
    "\n",
    "#Scale X-Data with Training Xs\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tnAu)\n",
    "X_tnS = scaler.transform(X_tnAu)\n",
    "X_ttS = scaler.transform(X_tt)\n",
    "\n",
    "\n",
    "X_tnh = np.apply_along_axis(fwht, axis=1, arr=X_tnS)\n",
    "X_tth = np.apply_along_axis(fwht, axis=1, arr=X_ttS)\n",
    "X_tnh = X_tnh.astype('float32')\n",
    "X_tth = X_tth.astype('float32')\n",
    "\n",
    "#Encode y-Data with Training ys\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_tnAu)\n",
    "y_tn_e = encoder.transform(y_tnAu)\n",
    "y_tn_p = np_utils.to_categorical(y_tn_e, num_classes = len(labels))\n",
    "y_tt_e = encoder.transform(y_tt)\n",
    "y_tt_p = np_utils.to_categorical(y_tt_e, num_classes = len(labels))\n",
    "\n",
    "#Reshape All Data to a 3D Tensor of Shape [Number of Spectra, Number of Timesteps(1), Number of Wavelengths]\n",
    "X_tn_p = X_tnh.reshape(X_tnh.shape[0], X_tnh.shape[1], 1)\n",
    "X_tt_p = X_tth.reshape(X_tth.shape[0], X_tth.shape[1], 1)\n",
    "\n",
    "y_tnT = tf.convert_to_tensor(y_tn_p)\n",
    "y_ttT = tf.convert_to_tensor(y_tt_p)\n",
    "X_tnT = tf.convert_to_tensor(X_tn_p)\n",
    "X_ttT = tf.convert_to_tensor(X_tt_p)\n",
    "\n",
    "\n",
    "display(X_tnT.shape)\n",
    "display(y_tnT.shape)\n",
    "display(X_ttT.shape)\n",
    "display(y_ttT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e029d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 2.8483 - accuracy: 0.8850 - val_loss: 9.5927e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 8s 119ms/step - loss: 3.0202e-05 - accuracy: 1.0000 - val_loss: 2.2254e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 7s 103ms/step - loss: 9.2763e-06 - accuracy: 1.0000 - val_loss: 1.0594e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 8s 120ms/step - loss: 9.0701e-06 - accuracy: 1.0000 - val_loss: 9.8067e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 4.5109e-06 - accuracy: 1.0000 - val_loss: 6.3963e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 7s 112ms/step - loss: 3.1261e-06 - accuracy: 1.0000 - val_loss: 4.6644e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 7s 108ms/step - loss: 2.4036e-06 - accuracy: 1.0000 - val_loss: 3.5866e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 1.8412e-06 - accuracy: 1.0000 - val_loss: 2.9516e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 7s 114ms/step - loss: 1.5710e-06 - accuracy: 1.0000 - val_loss: 2.4767e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 7s 109ms/step - loss: 1.2459e-06 - accuracy: 1.0000 - val_loss: 2.1134e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 8s 128ms/step - loss: 1.1196e-06 - accuracy: 1.0000 - val_loss: 1.8586e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 7s 103ms/step - loss: 9.4547e-07 - accuracy: 1.0000 - val_loss: 1.6276e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 8s 119ms/step - loss: 8.1982e-07 - accuracy: 1.0000 - val_loss: 1.4485e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 8.1229e-07 - accuracy: 1.0000 - val_loss: 1.2831e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 8s 118ms/step - loss: 6.8660e-07 - accuracy: 1.0000 - val_loss: 1.1451e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 7s 114ms/step - loss: 6.0904e-07 - accuracy: 1.0000 - val_loss: 1.0242e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 7s 113ms/step - loss: 5.4620e-07 - accuracy: 1.0000 - val_loss: 9.2759e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 7s 114ms/step - loss: 4.9185e-07 - accuracy: 1.0000 - val_loss: 8.4474e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "48/64 [=====================>........] - ETA: 1s - loss: 4.2970e-07 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "#Multi-class Classification with Keras\n",
    " \n",
    "n_timesteps, n_features, n_outputs = X_tn_p.shape[1], X_tn_p.shape[2], y_tn_p.shape[1]\n",
    "\n",
    "#Define Sequential Model - 1 Convolution Layer, 1 Dropout Layer, 1 Flatten Layer, 2 Dense Layers\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Implement EarlyStopping\n",
    "stopper = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", mode = 'min',\\\n",
    "                                           patience = 2, verbose = 1, restore_best_weights = True)\n",
    "\n",
    "#Fit Model\n",
    "model.fit(X_tnT, y_tnT, epochs=epochs, batch_size=batch_size, verbose=verbose,  validation_split=0.2, callbacks = stopper)\n",
    "\n",
    "#Evaluate Model\n",
    "_, HTaccuracy = model.evaluate(X_ttT, y_ttT, batch_size=batch_size, verbose=verbose)\n",
    "display(HTaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Prediction\n",
    "HTypred = model.predict(X_ttT)\n",
    "HTypred = tf.argmax(input = HTypred, axis = 1).numpy()\n",
    "HTypred = encoder.inverse_transform(HTypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ca327",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlayer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "convlayer.summary()\n",
    "\n",
    "spectra = X_ttT[n, :, 0]\n",
    "specvec.append(spectra)\n",
    "spectra = tf.reshape(spectra, (1, len(spectra), 1))\n",
    "\n",
    "HTfeature_maps = convlayer.predict(spectra)\n",
    "display(HTfeature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "display(SCypred)\n",
    "CMSC = confusion_matrix(ytruth, SCypred, labels = labels)\n",
    "CMFT = confusion_matrix(ytruth, FTypred, labels = labels)\n",
    "CMHT = confusion_matrix(ytruth, HTypred, labels = labels)\n",
    "display(SCaccuracy, FTaccuracy, HTaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, sharey = True, figsize = [15, 5])\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "\n",
    "pcm = axs[0].pcolor(CMSC, edgecolors = 'k', cmap = 'gist_heat_r')\n",
    "plt.gca().invert_yaxis()\n",
    "axs[0].set_xticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels)\n",
    "axs[0].set_yticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels)\n",
    "axs[0].set_ylabel(\"Actual Condition\")\n",
    "axs[0].set_xlabel(\"Predicted Condition\")\n",
    "axs[0].xaxis.set_label_position('top') \n",
    "axs[0].set_title('Raw Data');\n",
    "\n",
    "axs[1].pcolor(CMFT, edgecolors = 'k', cmap = 'gist_heat_r');\n",
    "plt.gca().invert_yaxis()\n",
    "axs[1].set_xticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels)\n",
    "axs[1].set_title('Fourier Transform');\n",
    "axs[1].set_xlabel(\"Predicted Condition\")\n",
    "axs[1].xaxis.set_label_position('top')\n",
    "\n",
    "axs[2].pcolor(CMHT, edgecolors = 'k', cmap = 'gist_heat_r')\n",
    "plt.gca().invert_yaxis()\n",
    "axs[2].set_xticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels);\n",
    "axs[2].set_title('Walsh Hadamard Transform');\n",
    "axs[2].set_xlabel(\"Predicted Condition\")\n",
    "axs[2].xaxis.set_label_position('top')\n",
    "\n",
    "fig.colorbar(pcm, ax = axs[:], location = 'bottom', label = 'Number of Assignments');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d30a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
