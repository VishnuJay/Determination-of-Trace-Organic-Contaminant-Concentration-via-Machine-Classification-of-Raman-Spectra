{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5953c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import KeyFunctions as me\n",
    "import tensorflow as tf\n",
    "RandState = 92\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, MaxPooling2D, LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b201c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Full Triclosan Dataset\n",
    "df, labels = me.ConstructCombinedChlorDataset()\n",
    "\n",
    "[train, test] = train_test_split(df, random_state = RandState, shuffle = True, train_size = 0.8)\n",
    "\n",
    "y_tn = train.index\n",
    "y_tt = test.index\n",
    "X_tt = test.to_numpy()\n",
    "X_tn = train.to_numpy()\n",
    "\n",
    "#Augment Data to 4000 Spectra\n",
    "X_tnAu, y_tnAu = me.AugmentData(X_tn, y_tn, 4000, df.columns.to_numpy(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdef8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Training Parameters\n",
    "verbose = 1\n",
    "epochsvec = [5, 20, 50]\n",
    "batch_sizevec = [10, 50, 100]\n",
    "epochs = epochsvec[1]\n",
    "batch_size = batch_sizevec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479b91a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 618, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 618, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale X-Data with Training Xs\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tnAu)\n",
    "X_tnS = scaler.transform(X_tnAu)\n",
    "X_ttS = scaler.transform(X_tt)\n",
    "\n",
    "#Encode y-Data with Training ys\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_tnAu)\n",
    "y_tn_e = encoder.transform(y_tnAu)\n",
    "y_tn_p = np_utils.to_categorical(y_tn_e, num_classes = len(labels))\n",
    "y_tt_e = encoder.transform(y_tt)\n",
    "y_tt_p = np_utils.to_categorical(y_tt_e, num_classes = len(labels))\n",
    "\n",
    "\n",
    "#Reshape All Data to a 3D Tensor of Shape [Number of Spectra, Number of Timesteps(1), Number of Wavelengths]\n",
    "X_tn_p = X_tnS.reshape(X_tnS.shape[0], X_tnS.shape[1], 1)\n",
    "X_tt_p = X_ttS.reshape(X_ttS.shape[0], X_ttS.shape[1], 1)\n",
    "\n",
    "y_tnT = tf.convert_to_tensor(y_tn_p)\n",
    "y_ttT = tf.convert_to_tensor(y_tt_p)\n",
    "X_tnT = tf.convert_to_tensor(X_tn_p)\n",
    "X_ttT = tf.convert_to_tensor(X_tt_p)\n",
    "\n",
    "display(X_tnT.shape)\n",
    "display(y_tnT.shape)\n",
    "display(X_ttT.shape)\n",
    "display(y_ttT.shape)\n",
    "\n",
    "ytruth = tf.argmax(input = y_ttT, axis = 1).numpy()\n",
    "ytruth = encoder.inverse_transform(ytruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374fecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 15s 208ms/step - loss: 1.0321 - accuracy: 0.5128 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 13s 199ms/step - loss: 0.5257 - accuracy: 0.8134 - val_loss: 0.3213 - val_accuracy: 0.8625\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 13s 200ms/step - loss: 0.3573 - accuracy: 0.8706 - val_loss: 0.1580 - val_accuracy: 0.9600\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 12s 195ms/step - loss: 0.2107 - accuracy: 0.9184 - val_loss: 0.0507 - val_accuracy: 0.9887\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 13s 198ms/step - loss: 0.0727 - accuracy: 0.9825 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.4075 - accuracy: 0.6459 - val_loss: 1.4320 - val_accuracy: 0.4162\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 13s 199ms/step - loss: 0.9493 - accuracy: 0.5663 - val_loss: 0.7214 - val_accuracy: 0.7113\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.4407 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8999999761581421"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Multi-class Classification with Keras\n",
    " \n",
    "n_timesteps, n_features, n_outputs = X_tn_p.shape[1], X_tn_p.shape[2], y_tn_p.shape[1]\n",
    "\n",
    "#Define Sequential Model - 1 Convolution Layer, 1 Dropout Layer, 1 Flatten Layer, 2 Dense Layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(100 ,input_shape=(n_timesteps,n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Implement EarlyStopping\n",
    "stopper = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",patience = 2,verbose = 0, restore_best_weights = True)\n",
    "\n",
    "#Fit Model\n",
    "model.fit(X_tnT, y_tnT, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split = 0.2, callbacks = stopper)\n",
    "\n",
    "#Evaluate Model\n",
    "_, SCaccuracy = model.evaluate(X_ttT, y_ttT, batch_size=batch_size, verbose=verbose)\n",
    "display(SCaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ccf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Prediction\n",
    "SCypred = model.predict(X_ttT)\n",
    "SCypred = tf.argmax(input = SCypred, axis = 1).numpy()\n",
    "SCypred = encoder.inverse_transform(SCypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b7e0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.65276781e-01, -1.53252080e-01, -2.38166258e-01,\n",
       "        -2.40163028e-01, -2.48533040e-01, -2.10931107e-01,\n",
       "        -4.00275439e-02,  3.59446734e-01,  3.89233440e-01,\n",
       "        -8.03895965e-02,  6.61663041e-02,  2.24283244e-02,\n",
       "         2.45834161e-02,  5.87311864e-01,  4.58715111e-02,\n",
       "        -3.47208321e-01, -2.11884558e-01,  7.27094039e-02,\n",
       "         1.07905284e-01,  1.85271055e-01,  4.36625451e-01,\n",
       "         2.39184901e-01,  4.64593977e-01, -3.96063505e-03,\n",
       "         8.28803405e-02, -1.27142027e-01, -2.88863868e-01,\n",
       "        -2.84596831e-01,  2.60387421e-01,  7.36975446e-02,\n",
       "        -1.10140488e-01,  2.96321549e-02, -2.93844253e-01,\n",
       "         1.33324414e-01, -3.78717035e-01,  1.06996670e-01,\n",
       "        -6.34086726e-04,  9.19287205e-02,  6.96696877e-01,\n",
       "         3.20415527e-01, -4.20117080e-01, -1.11371353e-01,\n",
       "         1.12547204e-01,  3.04387033e-01, -7.04885349e-02,\n",
       "        -2.87801176e-01, -4.20978397e-01,  9.55018960e-03,\n",
       "        -3.63112301e-01,  1.46847397e-01, -1.77345991e-01,\n",
       "        -2.60745496e-01,  3.43006432e-01,  5.09512722e-01,\n",
       "         2.50546094e-02,  1.31719500e-01,  1.35501996e-01,\n",
       "        -6.79683089e-02,  4.49716538e-01,  6.09649777e-01,\n",
       "         1.49072602e-01, -9.57180038e-02,  7.33933076e-02,\n",
       "         5.79007149e-01,  4.50968713e-01,  3.13050568e-01,\n",
       "        -2.11165801e-01,  2.39223540e-01, -5.60925305e-01,\n",
       "         5.61478734e-01,  3.58231455e-01, -2.84584370e-02,\n",
       "         7.62264356e-02,  4.61471267e-02, -1.07246950e-01,\n",
       "        -3.76877338e-01, -1.77619413e-01,  3.44350301e-02,\n",
       "        -3.13478947e-01,  2.11935446e-01,  4.12265301e-01,\n",
       "         1.33062735e-01,  2.26163551e-01, -1.91117764e-01,\n",
       "         1.41036406e-01,  9.98306274e-02, -4.39997204e-02,\n",
       "         1.26495376e-01,  1.83394194e-01,  3.98894176e-02,\n",
       "         2.34892994e-01,  5.14352322e-02,  1.58192679e-01,\n",
       "        -2.27005467e-01, -2.00120240e-01,  4.29564774e-01,\n",
       "        -2.57420335e-02, -4.84974869e-02,  1.99804585e-02,\n",
       "         2.06977621e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract Convolution Feature Maps\n",
    "convlayer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "\n",
    "spectra = X_ttT[n, :, 0]\n",
    "specvec = list()\n",
    "specvec.append(spectra)\n",
    "spectra = tf.reshape(spectra, (1, len(spectra), 1))\n",
    "\n",
    "SCfeature_maps = convlayer.predict(spectra)\n",
    "display(SCfeature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53fd3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 1236, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1236, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tnAu)\n",
    "X_tnAu = scaler.transform(X_tnAu)\n",
    "X_tt = scaler.transform(X_tt)\n",
    "\n",
    "#Apply Fourier Transform to Training and Testing Data\n",
    "X_tnf = np.apply_along_axis(np.fft.fft, axis=1, arr=X_tnAu)\n",
    "X_ttf = np.apply_along_axis(np.fft.fft, axis=1, arr=X_tt)\n",
    "\n",
    "#Combine Real and Imaginary Part of FT in form [real, imaginary]\n",
    "X_tnf = np.append(X_tnf.real, X_tnf.imag, axis = 1)\n",
    "X_ttf = np.append(X_ttf.real, X_ttf.imag, axis = 1)\n",
    "X_tnf= X_tnf.astype('float32')\n",
    "X_ttf= X_ttf.astype('float32')\n",
    "\n",
    "#Scale X-Data with Training Xs\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_tnf)\n",
    "#X_tnf = scaler.transform(X_tnf)\n",
    "#X_ttf = scaler.transform(X_ttf)\n",
    "\n",
    "#Encode y-Data with Training ys\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_tnAu)\n",
    "y_tn_e = encoder.transform(y_tnAu)\n",
    "y_tn_p = np_utils.to_categorical(y_tn_e, num_classes = len(labels))\n",
    "y_tt_e = encoder.transform(y_tt)\n",
    "y_tt_p = np_utils.to_categorical(y_tt_e, num_classes = len(labels))\n",
    "\n",
    "#Reshape All Data to a 3D Tensor of Shape [Number of Spectra, Number of Timesteps(1), Number of Wavelengths]\n",
    "X_tn_p = X_tnf.reshape(X_tnf.shape[0], X_tnf.shape[1], 1)\n",
    "X_tt_p = X_ttf.reshape(X_ttf.shape[0], X_ttf.shape[1], 1)\n",
    "\n",
    "y_tnT = tf.convert_to_tensor(y_tn_p)\n",
    "y_ttT = tf.convert_to_tensor(y_tt_p)\n",
    "X_tnT = tf.convert_to_tensor(X_tn_p)\n",
    "X_ttT = tf.convert_to_tensor(X_tt_p)\n",
    "\n",
    "\n",
    "display(X_tnT.shape)\n",
    "display(y_tnT.shape)\n",
    "display(X_ttT.shape)\n",
    "display(y_ttT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e552db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 29s 424ms/step - loss: 1.1614 - accuracy: 0.5700 - val_loss: 0.5177 - val_accuracy: 0.8575\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 26s 403ms/step - loss: 0.3255 - accuracy: 0.9106 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.0819 - accuracy: 0.9834 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.0325 - accuracy: 0.9947 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 26s 404ms/step - loss: 0.0207 - accuracy: 0.9966 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.0121 - accuracy: 0.9984 - val_loss: 4.7284e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 26s 410ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 2.7825e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 26s 406ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 3.4817e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 26s 412ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.3321e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 26s 406ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 1.2898e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 26s 405ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.4670e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 4.3281e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 26s 405ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 4.1103e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 26s 412ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 2.7627e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 1.6299e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 26s 404ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 1.3278e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 26s 406ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 9.2360e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.5649e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 25s 387ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.3549e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.5888e-06 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.4270 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6000000238418579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Multi-class Classification with Keras\n",
    " \n",
    "n_timesteps, n_features, n_outputs = X_tn_p.shape[1], X_tn_p.shape[2], y_tn_p.shape[1]\n",
    "\n",
    "#Define Sequential Model - 1 Convolution Layer, 1 Dropout Layer, 1 Flatten Layer, 2 Dense Layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(100 ,input_shape=(n_timesteps,n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Implement EarlyStopping\n",
    "stopper = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",patience = 3,verbose = 0, restore_best_weights = True)\n",
    "\n",
    "#Fit Model\n",
    "model.fit(X_tnT, y_tnT, epochs=epochs, batch_size=batch_size, verbose=verbose,  validation_split=0.2, callbacks = stopper)\n",
    "\n",
    "#Evaluate Model\n",
    "_, FTaccuracy = model.evaluate(X_ttT, y_ttT, batch_size=batch_size, verbose=verbose)\n",
    "display(FTaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54173aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Prediction\n",
    "FTypred = model.predict(X_ttT)\n",
    "FTypred = tf.argmax(input = FTypred, axis = 1).numpy()\n",
    "FTypred = encoder.inverse_transform(FTypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0580f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1_input (InputLayer)    [(None, 1236, 1)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               40800     \n",
      "=================================================================\n",
      "Total params: 40,800\n",
      "Trainable params: 40,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-9.77664173e-01, -5.49174488e-01,  5.42899594e-03,\n",
       "        -4.90118452e-07, -3.03509235e-01, -3.30201983e-02,\n",
       "         2.98233926e-01, -4.42051828e-01,  9.99975204e-01,\n",
       "        -3.54715894e-06,  9.97323096e-01,  1.23253586e-02,\n",
       "        -9.24764425e-02,  2.16065440e-02, -1.05916476e-03,\n",
       "        -2.73406622e-03,  5.58944943e-04, -5.75670123e-01,\n",
       "        -7.58354247e-01, -4.09328431e-01,  5.86289400e-03,\n",
       "        -1.15512181e-02,  8.45666766e-01, -8.53298724e-01,\n",
       "        -9.75132763e-01,  2.33501837e-01, -2.27872297e-01,\n",
       "         6.08087838e-01, -1.22055913e-04,  4.92720082e-02,\n",
       "         4.35074493e-02,  7.46550620e-01, -1.39393774e-06,\n",
       "        -9.43882823e-01, -4.89304874e-10, -4.90143783e-02,\n",
       "        -8.08172882e-01,  7.82629371e-01, -9.99993503e-01,\n",
       "        -2.96809454e-03, -7.30073850e-07,  1.33721669e-05,\n",
       "        -1.46442831e-01, -7.79328585e-01, -1.19287055e-02,\n",
       "        -9.93099451e-01, -6.57591328e-04,  2.57290989e-08,\n",
       "        -2.49803260e-01, -5.81365079e-03,  9.39225912e-01,\n",
       "         9.99934435e-01, -3.21052164e-01, -1.23702466e-01,\n",
       "         2.41248429e-01, -9.99699712e-01,  9.92011011e-01,\n",
       "        -3.24343711e-01, -5.18022418e-01,  8.91195238e-02,\n",
       "         9.99487698e-01, -8.08716536e-01, -1.67759567e-01,\n",
       "        -2.97778577e-01, -9.28650260e-01,  8.81490558e-02,\n",
       "         3.63296044e-06,  9.82946157e-01,  8.84678006e-01,\n",
       "         8.40612408e-03,  1.64214894e-01, -7.20592618e-01,\n",
       "        -5.87970138e-01, -1.04373232e-01, -5.99473715e-04,\n",
       "         1.55489847e-01, -1.68781644e-05, -1.69783802e-04,\n",
       "         2.64310353e-02, -4.15563583e-04, -6.04371846e-01,\n",
       "         3.86495218e-02, -9.85124052e-01,  3.85404587e-01,\n",
       "        -6.08463943e-01, -5.09507954e-01, -2.39407588e-02,\n",
       "        -4.59792512e-03,  6.89188614e-02,  1.39804035e-01,\n",
       "        -6.49452507e-01, -9.87051606e-01,  4.12380427e-01,\n",
       "        -1.31319286e-02, -7.96119217e-03, -1.08047193e-02,\n",
       "        -1.93492923e-07,  3.24129534e-04, -7.60528922e-01,\n",
       "         9.60366845e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convlayer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "convlayer.summary()\n",
    "\n",
    "spectra = X_ttT[n, :, 0]\n",
    "specvec.append(spectra)\n",
    "spectra = tf.reshape(spectra, (1, len(spectra), 1))\n",
    "\n",
    "FTfeature_maps = convlayer.predict(spectra)\n",
    "display(FTfeature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "756a0320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 1024, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4000, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1024, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Apply Welsh-Hadamard Transform to Training and Testing Data\n",
    "from sympy.discrete.transforms import fwht, ifwht\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tnAu)\n",
    "X_tnAu = scaler.transform(X_tnAu)\n",
    "X_tt = scaler.transform(X_tt)\n",
    "\n",
    "X_tnh = np.apply_along_axis(fwht, axis=1, arr=X_tnAu)\n",
    "X_tth = np.apply_along_axis(fwht, axis=1, arr=X_tt)\n",
    "X_tnh = X_tnh.astype('float32')\n",
    "X_tth = X_tth.astype('float32')\n",
    "\n",
    "#Encode y-Data with Training ys\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_tnAu)\n",
    "y_tn_e = encoder.transform(y_tnAu)\n",
    "y_tn_p = np_utils.to_categorical(y_tn_e, num_classes = len(labels))\n",
    "y_tt_e = encoder.transform(y_tt)\n",
    "y_tt_p = np_utils.to_categorical(y_tt_e, num_classes = len(labels))\n",
    "\n",
    "#Reshape All Data to a 3D Tensor of Shape [Number of Spectra, Number of Timesteps(1), Number of Wavelengths]\n",
    "X_tn_p = X_tnh.reshape(X_tnh.shape[0], X_tnh.shape[1], 1)\n",
    "X_tt_p = X_tth.reshape(X_tth.shape[0], X_tth.shape[1], 1)\n",
    "\n",
    "y_tnT = tf.convert_to_tensor(y_tn_p)\n",
    "y_ttT = tf.convert_to_tensor(y_tt_p)\n",
    "X_tnT = tf.convert_to_tensor(X_tn_p)\n",
    "X_ttT = tf.convert_to_tensor(X_tt_p)\n",
    "\n",
    "\n",
    "display(X_tnT.shape)\n",
    "display(y_tnT.shape)\n",
    "display(X_ttT.shape)\n",
    "display(y_ttT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e029d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 25s 366ms/step - loss: 1.1500 - accuracy: 0.5016 - val_loss: 0.5531 - val_accuracy: 0.7337\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 23s 355ms/step - loss: 0.3527 - accuracy: 0.8637 - val_loss: 0.1393 - val_accuracy: 0.9800\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 23s 360ms/step - loss: 0.0782 - accuracy: 0.9841 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 23s 356ms/step - loss: 0.1079 - accuracy: 0.9622 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 23s 353ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 9.7287e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 22s 351ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 5.0576e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 23s 362ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.2245e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 23s 353ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 2.4214e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5126e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 23s 355ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1674e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 23s 357ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.6011e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 23s 353ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.1841e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 23s 359ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.4958e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 24s 367ms/step - loss: 7.1633e-04 - accuracy: 1.0000 - val_loss: 3.4143e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 24s 368ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.7114e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 23s 357ms/step - loss: 5.6279e-04 - accuracy: 1.0000 - val_loss: 2.2457e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 22s 350ms/step - loss: 6.8715e-04 - accuracy: 1.0000 - val_loss: 2.2414e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 23s 359ms/step - loss: 4.8197e-04 - accuracy: 1.0000 - val_loss: 1.8409e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 23s 355ms/step - loss: 3.9412e-04 - accuracy: 1.0000 - val_loss: 1.3960e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 9.5799 - accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20000000298023224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Multi-class Classification with Keras\n",
    " \n",
    "n_timesteps, n_features, n_outputs = X_tn_p.shape[1], X_tn_p.shape[2], y_tn_p.shape[1]\n",
    "\n",
    "#Define Sequential Model - 1 Convolution Layer, 1 Dropout Layer, 1 Flatten Layer, 2 Dense Layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(100 ,input_shape=(n_timesteps,n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Implement EarlyStopping\n",
    "stopper = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", mode = 'min',\\\n",
    "                                           patience = 3, verbose = 1, restore_best_weights = True)\n",
    "\n",
    "#Fit Model\n",
    "model.fit(X_tnT, y_tnT, epochs=epochs, batch_size=batch_size, verbose=verbose,  validation_split=0.2, callbacks = stopper)\n",
    "\n",
    "#Evaluate Model\n",
    "_, HTaccuracy = model.evaluate(X_ttT, y_ttT, batch_size=batch_size, verbose=verbose)\n",
    "display(HTaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d0d1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A48FD43790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#Make Prediction\n",
    "HTypred = model.predict(X_ttT)\n",
    "HTypred = tf.argmax(input = HTypred, axis = 1).numpy()\n",
    "HTypred = encoder.inverse_transform(HTypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13ca327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2_input (InputLayer)    [(None, 1024, 1)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               40800     \n",
      "=================================================================\n",
      "Total params: 40,800\n",
      "Trainable params: 40,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A4AA8A8430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01274807,  0.19044362, -0.07452521, -0.446113  ,  0.44652647,\n",
       "        -0.26214504, -0.03176278,  0.4629086 , -0.45299742, -0.09409791,\n",
       "         0.33223376, -0.17287397, -0.37630644,  0.47125298, -0.12499189,\n",
       "        -0.033601  ,  0.4021436 ,  0.15646656, -0.06739801,  0.25530332,\n",
       "         0.02898117, -0.5389621 , -0.6869321 , -0.7417064 , -0.57725704,\n",
       "        -0.32479483, -0.15225527,  0.11103939, -0.01692522, -0.04953971,\n",
       "        -0.47131923,  0.13657671, -0.10829187,  0.27663654,  0.8589099 ,\n",
       "        -0.34064725, -0.5078458 ,  0.00718418, -0.74638814, -0.3387687 ,\n",
       "         0.18229797, -0.01558028, -0.3978289 , -0.46831924, -0.21703838,\n",
       "         0.18554422, -0.48355672,  0.04676195,  0.13926847,  0.5152574 ,\n",
       "        -0.17458393,  0.37573904,  0.12632236, -0.09540264, -0.31644553,\n",
       "         0.6043547 , -0.14564122,  0.00524325, -0.22665152, -0.3479148 ,\n",
       "        -0.21876983, -0.29953438, -0.06969064, -0.8986668 ,  0.04659162,\n",
       "        -0.35528445, -0.10511722, -0.08271766,  0.10024074,  0.4978491 ,\n",
       "        -0.0701801 , -0.4210711 , -0.20060888, -0.7597951 , -0.16273466,\n",
       "        -0.34568363, -0.00258595,  0.5789298 , -0.4389811 ,  0.01898475,\n",
       "        -0.01246453, -0.59820294, -0.00614177, -0.7185906 , -0.17723723,\n",
       "         0.13722351,  0.00567065, -0.4761467 ,  0.17343664, -0.39721552,\n",
       "        -0.4111531 ,  0.15960121, -0.26579767, -0.6740449 , -0.37161154,\n",
       "        -0.00801686,  0.06102882, -0.25972354, -0.43445054,  0.77792245]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convlayer = tf.keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "convlayer.summary()\n",
    "\n",
    "spectra = X_ttT[n, :, 0]\n",
    "specvec.append(spectra)\n",
    "spectra = tf.reshape(spectra, (1, len(spectra), 1))\n",
    "\n",
    "HTfeature_maps = convlayer.predict(spectra)\n",
    "display(HTfeature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0107edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10-3', '10-7', '10-7', '10-4', '10-5', '10-7', '10-5', '10-6',\n",
       "       '10-3', '10-4'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8999999761581421"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6000000238418579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.30000001192092896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "display(SCypred)\n",
    "CMSC = confusion_matrix(ytruth, SCypred, labels = labels)\n",
    "CMFT = confusion_matrix(ytruth, FTypred, labels = labels)\n",
    "CMHT = confusion_matrix(ytruth, HTypred, labels = labels)\n",
    "display(SCaccuracy, FTaccuracy, HTaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79c1b1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, sharey = True, figsize = [15, 5])\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "\n",
    "pcm = axs[0].pcolor(CMSC, edgecolors = 'k', cmap = 'gist_heat_r')\n",
    "plt.gca().invert_yaxis()\n",
    "axs[0].set_xticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels)\n",
    "axs[0].set_yticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels)\n",
    "axs[0].set_ylabel(\"Actual Condition\")\n",
    "axs[0].set_xlabel(\"Predicted Condition\")\n",
    "axs[0].xaxis.set_label_position('top') \n",
    "axs[0].set_title('Raw Data');\n",
    "\n",
    "axs[1].pcolor(CMFT, edgecolors = 'k', cmap = 'gist_heat_r');\n",
    "plt.gca().invert_yaxis()\n",
    "axs[1].set_xticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels)\n",
    "axs[1].set_title('Fourier Transform');\n",
    "axs[1].set_xlabel(\"Predicted Condition\")\n",
    "axs[1].xaxis.set_label_position('top')\n",
    "\n",
    "axs[2].pcolor(CMHT, edgecolors = 'k', cmap = 'gist_heat_r')\n",
    "plt.gca().invert_yaxis()\n",
    "axs[2].set_xticks(ticks = np.linspace(0.5, len(labels)-0.5, num = len(labels)), labels = labels);\n",
    "axs[2].set_title('Walsh Hadamard Transform');\n",
    "axs[2].set_xlabel(\"Predicted Condition\")\n",
    "axs[2].xaxis.set_label_position('top')\n",
    "\n",
    "fig.colorbar(pcm, ax = axs[:], location = 'bottom', label = 'Number of Assignments');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d30a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
